---
layout: post
title: 标准建模流程(2): 变量选择
date: 2011-10-04 14:47
comments: true
categories: []
---
建模时不可避免会使用很多自造的变量，也会舍弃很多原本觉得会显著然而实际模型中却不够显著的变量。可靠的模型必定是建立在可靠的变量的基础上的，模型的输入变量很可能有很多，但这些变量对模型并非都是必须的。参照奥卡姆剃刀原则，我们的目标是使用尽可能少但必要的变量，使得模型效果显著。因此在选择时需慎重考虑，就我在使用中的经验简单总结原则如下：

<strong>必要性：</strong>变量的数目追求少而精，丢掉一些不重要的变量后，虽然可能使得估计有偏，但会更加稳定，预测精度也会提高。这因为当模型中变量增多时，可能在训练集中表现良好，但在测试集中却表现很差。增加变量会出现方差变低但偏差变高的情况（过拟合）。

<strong>共线性：</strong>当模型中某些变量存在严重相关性时，违反了高斯假定使得模型效果会受到很大影响，应综合考虑剔除其中部分变量：对若干共线性变量只保留其中一个主要的即可。

<strong>敏感性：</strong>某些变量对很多样本来说都一样，或者数值型变量在所有样本中变化尺度都很小，具有不敏感性，应考虑剔除不敏感的变量。

<strong>可解释性：</strong>当模型中的输入变量很多时，可能会混入一些无关的混淆变量，或者一些变量的正负符号与现实不符合，在模型中不具实际意义，难于解释，应剔除。

<strong>采集成本：</strong>当模型进入实施阶段后，如果变量太多可能存在有使样本的采集成本过大。而不同变量的采集成本不同，从经济性角度综合考虑后可保留若干。

在经典的回归分析中，变量选择主要有以下几种方法可供参考。

<strong>前进法：</strong>只进不出。每次引入一个最显著的变量，变量由少到多，直至没有可引入的变量为止。优点是计算量小，缺点是“终身制”，一旦引入就不再退出。

<strong>后退法：</strong>只出不进。先用全部变量建立回归方程，再逐个剔除最不显著变量，变量由多到少，直至没有可剔除变量为止。优点是每个变量都有展示自己的机会，缺点是计算量大，“一棍子打死”，一旦剔除就没机会再进入。

<strong>逐步回归法：</strong>有进有出。逐个引入变量，每引入一个变量后，对已入选变量逐个检验，剔除不再显著变量，再考虑引入，如此下去，直至无显著变量可引入，也无不显著变量可剔除为止。吸收了前进法与后退法的优点并克服了它们的不足，但要注意限制使其不会产生死循环。在R中实现的方法是step(my_ model), my_model可以是你拟合得到的任何lm类模型，使用非常方便。

&nbsp;
